{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d2e7dad-6b68-47bd-9b23-eb3f6c5edbf5",
   "metadata": {},
   "source": [
    "# Baseline Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "aa1d67a4-24eb-4e5a-b6e3-a34a21666232",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f915659-6f3c-42d7-89f4-f89d0bb4bd6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5a21859-01ce-4227-b06a-43c8d1739004",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c6ddcfd-931d-4298-beb4-8e55fa5a2fc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MASE\n",
    "def mean_absolute_scaled_error(y_true, y_pred):\n",
    "    n = len(y_true)\n",
    "\n",
    "    # Calculate MAE of the forecasts\n",
    "    mae_forecast = np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "    # Calculate MAE of the naive forecast\n",
    "    mae_naive = np.mean(np.abs(np.diff(y_true)))  # Diff calculates y_i - y_{i-1}\n",
    "\n",
    "    # Ensure denominator is not zero\n",
    "    if mae_naive == 0:\n",
    "        return np.inf  # Return infinity if naive MAE is zero\n",
    "\n",
    "    return mae_forecast / mae_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e67ddac1-3f83-454e-a6ae-6ba00dc150ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merge_B_ip = pd.read_csv('./data/merge_B_ip.csv', encoding = 'cp949')\n",
    "merge_C_ip = pd.read_csv('./data/merge_C_ip.csv', encoding = 'cp949')\n",
    "merge_D_ip = pd.read_csv('./data/merge_D_ip.csv', encoding = 'cp949')\n",
    "merge_E_ip = pd.read_csv('./data/merge_E_ip.csv', encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4a27985-6102-4700-b901-ab83c90e7fe0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_merged = pd.concat([merge_B_ip,merge_C_ip,merge_D_ip,merge_E_ip])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6bdaed3-ea1e-46ba-93a5-f760bfba1824",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = ['Stem Diameter', 'Petiole Length','Leaf Count', 'Leaf Length', 'Leaf Width', 'Fruit Count',\n",
    "       'Plant Height', 'Final Inflorescence Order','Inflorescence Flower Count', 'supplyEC', 'supplyPH', 'innerCO2',\n",
    "       'innerHum', 'innerTemp', 'innerSolar', 'Survey Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08b72953-459c-4bfc-a208-4791295dbbf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_merged = df_merged[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7503e789-dc87-4dbc-86aa-8de3edeb3733",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_merged['Survey Date'] = pd.to_datetime(df_merged['Survey Date'], format='%Y-%m-%d %H:%M')\n",
    "df_merged.set_index('Survey Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4b56213-bf6b-4d1f-b681-e76f63355cde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_merged.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e98a6cc-ec36-4d94-996f-5a4e732db398",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 171897 entries, 2023-10-06 00:00:00 to 2024-04-26 00:00:00\n",
      "Data columns (total 15 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   Stem Diameter               171897 non-null  float64\n",
      " 1   Petiole Length              171897 non-null  float64\n",
      " 2   Leaf Count                  171897 non-null  float64\n",
      " 3   Leaf Length                 171897 non-null  float64\n",
      " 4   Leaf Width                  171897 non-null  float64\n",
      " 5   Fruit Count                 171897 non-null  int64  \n",
      " 6   Plant Height                171897 non-null  float64\n",
      " 7   Final Inflorescence Order   171897 non-null  int64  \n",
      " 8   Inflorescence Flower Count  171897 non-null  int64  \n",
      " 9   supplyEC                    171897 non-null  float64\n",
      " 10  supplyPH                    171897 non-null  float64\n",
      " 11  innerCO2                    171897 non-null  float64\n",
      " 12  innerHum                    171897 non-null  float64\n",
      " 13  innerTemp                   171897 non-null  float64\n",
      " 14  innerSolar                  171897 non-null  float64\n",
      "dtypes: float64(12), int64(3)\n",
      "memory usage: 21.0 MB\n"
     ]
    }
   ],
   "source": [
    "df_merged.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77275b20-1475-4be2-9ba0-4d1534e5b28a",
   "metadata": {},
   "source": [
    "## train, validation, test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52a066f0-4c7b-4c96-90ff-b50591c00679",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(df_merged, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e3c3cb-7cf1-4f55-85dd-e1e2dbdc5441",
   "metadata": {},
   "source": [
    "## normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "697d6dfb-58cc-4741-a442-2c6171eae183",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train = scaler.fit_transform(train)\n",
    "test = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d649d8f8-fc72-4dcf-880c-01c9ee067f23",
   "metadata": {},
   "source": [
    "## x,y split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d345760f-007f-46ba-9404-7a366d353100",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((137517, 15), (34380, 15))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29d8c060-631c-4244-a44b-fc0715af486c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = train[:,9:]\n",
    "y_train = train[:,:9]\n",
    "x_test = test[:,9:]\n",
    "y_test = test[:,:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69deeee2-f514-4fe5-9a85-6f1f36ec317f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((137517, 6), (137517, 9))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ea0935d-3769-4424-b278-b4ce2889ad11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((34380, 6), (34380, 9))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1aefa6a-ce34-461b-a7ed-5ed254215de5",
   "metadata": {},
   "source": [
    "## baseline model selection (Machine Learning Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ffd925fd-cfda-4940-8cc3-c252d66ff5e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'RandomForestRegressor': RandomForestRegressor(),\n",
    "    'BaggingRegressor': BaggingRegressor(),\n",
    "    'XGBoostRegressor': XGBRegressor(),\n",
    "    'ElasticNetRegressor': ElasticNet(),\n",
    "    'KNNRegressor': KNeighborsRegressor()\n",
    "}\n",
    "\n",
    "# Dictionary to store the performance metrics for each model\n",
    "metrics = {\n",
    "    'Model': [],\n",
    "    'MSE': [],\n",
    "    'MASE': [],\n",
    "    'R2': [],\n",
    "    'RMSE': [],\n",
    "    'TrainingTime': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d847a350-3d05-4df5-85c9-4e2161c2249a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression - MSE: 1.1674969468904748\n",
      "LinearRegression - MASE: 0.8037111005905345\n",
      "LinearRegression - R2: -0.07158540449219485\n",
      "LinearRegression - RMSE: 1.0805077264371943\n",
      "LinearRegression - TrainingTime: 0.055400848388671875\n",
      "Model saved as ./save_models_all/LinearRegression_model.h5\n",
      "RandomForestRegressor - MSE: 0.7523184330678965\n",
      "RandomForestRegressor - MASE: 0.574745258365784\n",
      "RandomForestRegressor - R2: 0.18481869657942898\n",
      "RandomForestRegressor - RMSE: 0.8673629188914502\n",
      "RandomForestRegressor - TrainingTime: 56.91299891471863\n",
      "Model saved as ./save_models_all/RandomForestRegressor_model.h5\n",
      "BaggingRegressor - MSE: 0.7705234214978426\n",
      "BaggingRegressor - MASE: 0.5806203670658566\n",
      "BaggingRegressor - R2: 0.16650862182938664\n",
      "BaggingRegressor - RMSE: 0.877794635149841\n",
      "BaggingRegressor - TrainingTime: 5.741190433502197\n",
      "Model saved as ./save_models_all/BaggingRegressor_model.h5\n",
      "XGBoostRegressor - MSE: 0.810717847454322\n",
      "XGBoostRegressor - MASE: 0.6480363974830788\n",
      "XGBoostRegressor - R2: 0.1739676528225312\n",
      "XGBoostRegressor - RMSE: 0.9003987158222306\n",
      "XGBoostRegressor - TrainingTime: 3.4395179748535156\n",
      "Model saved as ./save_models_all/XGBoostRegressor_model.h5\n",
      "ElasticNetRegressor - MSE: 1.2885764724098023\n",
      "ElasticNetRegressor - MASE: 0.8533996455417383\n",
      "ElasticNetRegressor - R2: -0.208267724270134\n",
      "ElasticNetRegressor - RMSE: 1.1351548231011497\n",
      "ElasticNetRegressor - TrainingTime: 0.03047466278076172\n",
      "Model saved as ./save_models_all/ElasticNetRegressor_model.h5\n",
      "KNNRegressor - MSE: 0.8522655777012045\n",
      "KNNRegressor - MASE: 0.6222550628554568\n",
      "KNNRegressor - R2: 0.08273552209845889\n",
      "KNNRegressor - RMSE: 0.9231823101106328\n",
      "KNNRegressor - TrainingTime: 0.20826005935668945\n",
      "Model saved as ./save_models_all/KNNRegressor_model.h5\n",
      "                   Model       MSE      MASE        R2      RMSE  TrainingTime\n",
      "0       LinearRegression  1.167497  0.803711 -0.071585  1.080508      0.055401\n",
      "1  RandomForestRegressor  0.752318  0.574745  0.184819  0.867363     56.912999\n",
      "2       BaggingRegressor  0.770523  0.580620  0.166509  0.877795      5.741190\n",
      "3       XGBoostRegressor  0.810718  0.648036  0.173968  0.900399      3.439518\n",
      "4    ElasticNetRegressor  1.288576  0.853400 -0.208268  1.135155      0.030475\n",
      "5           KNNRegressor  0.852266  0.622255  0.082736  0.923182      0.208260\n"
     ]
    }
   ],
   "source": [
    "# Directory to save model weights\n",
    "save_model_path = './save_models_all'\n",
    "os.makedirs(save_model_path, exist_ok=True)  # Create the directory if it does not exist\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    # Record the start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    # Record the end time\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculate training time\n",
    "    training_time = end_time - start_time\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Calculate performance metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mase = mean_absolute_scaled_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    # Store the metrics\n",
    "    metrics['Model'].append(name)\n",
    "    metrics['MSE'].append(mse)\n",
    "    metrics['MASE'].append(mase)\n",
    "    metrics['R2'].append(r2)\n",
    "    metrics['RMSE'].append(rmse)\n",
    "    metrics['TrainingTime'].append(training_time)\n",
    "\n",
    "    # Print the metrics\n",
    "    print(f'{name} - MSE: {mse}')\n",
    "    print(f'{name} - MASE: {mase}')\n",
    "    print(f'{name} - R2: {r2}')\n",
    "    print(f'{name} - RMSE: {rmse}')\n",
    "    print(f'{name} - TrainingTime: {training_time}')\n",
    "\n",
    "    # Save the model weights\n",
    "    model_filename = os.path.join(save_model_path, f'{name}_model.h5')  # Changed extension to .pkl for compatibility\n",
    "    joblib.dump(model, model_filename)\n",
    "    print(f'Model saved as {model_filename}')\n",
    "\n",
    "# Convert the metrics dictionary to a DataFrame for a cleaner display\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "print(metrics_df)\n",
    "\n",
    "# Save the metrics to a CSV file\n",
    "metrics_df.to_csv('result_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "37834eb0-043b-41a0-b089-d410d160a010",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137517, 6)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93f3517-2594-44fe-8504-8463063ef8c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## baseline model selection (deep learning models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c88dee9-a57b-4670-837e-2edcb2e71596",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Model Definitions (with EarlyStopping)\n",
    "def create_model_1():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(100, activation='tanh', input_shape=(x_train.shape[1],)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(100, activation='tanh'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(100, activation='tanh'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(y_train.shape[1])\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mse')\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    return model, early_stopping  # Return both the model and the callback\n",
    "\n",
    "def create_model_2():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.SimpleRNN(100, activation='tanh', return_sequences=True),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.SimpleRNN(100, activation='tanh'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(y_train.shape[1])\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mse')\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    return model, early_stopping\n",
    "\n",
    "def create_model_3():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(100, activation='tanh', return_sequences=True),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.LSTM(100, activation='tanh'),\n",
    "        tf.keras.layers.Dense(100, activation='sigmoid'), \n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(y_train.shape[1])  \n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mse')\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    return model, early_stopping\n",
    "\n",
    "def create_model_4():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.GRU(100, activation='tanh', return_sequences=True),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.GRU(100, activation='tanh'),\n",
    "        tf.keras.layers.Dense(100, activation='sigmoid'), \n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(y_train.shape[1])  \n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mse')\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    return model, early_stopping\n",
    "\n",
    "\n",
    "def reshape_for_rnn(X):\n",
    "    # Assuming X has shape (num_samples, num_features) for ANN\n",
    "    num_samples = X.shape[0]\n",
    "    time_steps = 1  # If each sample is a single time step\n",
    "    num_features = X.shape[1]\n",
    "    return X.reshape(num_samples, time_steps, num_features)\n",
    "\n",
    "\n",
    "# Create KerasRegressor Objects\n",
    "model_1, early_stopping_1 = create_model_1()\n",
    "model_1_regressor = KerasRegressor(\n",
    "    build_fn=lambda: model_1,  epochs=100,  batch_size=32, verbose=0, callbacks=[early_stopping_1] \n",
    ")\n",
    "\n",
    "model_2, early_stopping_2 = create_model_2()\n",
    "model_2_regressor = KerasRegressor(\n",
    "    build_fn=lambda: model_2, epochs=100, batch_size=32, verbose=0, callbacks=[early_stopping_2]\n",
    ")\n",
    "\n",
    "model_3, early_stopping_3 = create_model_3()\n",
    "model_3_regressor = KerasRegressor(\n",
    "    build_fn=lambda: model_3, epochs=100, batch_size=32, verbose=0, callbacks=[early_stopping_3]\n",
    ")\n",
    "\n",
    "model_4, early_stopping_4 = create_model_4()\n",
    "model_4_regressor = KerasRegressor(\n",
    "    build_fn=lambda: model_4, epochs=100, batch_size=32, verbose=0, callbacks=[early_stopping_4]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Pipeline (Updated)\n",
    "pipe_1 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', model_1_regressor)\n",
    "])\n",
    "\n",
    "    \n",
    "pipe_2 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('reshape', FunctionTransformer(reshape_for_rnn)),  # Add reshaping step\n",
    "    ('model', model_2_regressor)\n",
    "])\n",
    "\n",
    "pipe_3 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('reshape', FunctionTransformer(reshape_for_rnn)), \n",
    "    ('model', model_3_regressor)\n",
    "])\n",
    "\n",
    "pipe_4 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('reshape', FunctionTransformer(reshape_for_rnn)), \n",
    "    ('model', model_4_regressor)\n",
    "])\n",
    "\n",
    "\n",
    "# Training\n",
    "pipe_1.fit(x_train, y_train, model__validation_split=0.2)  \n",
    "pipe_2.fit(x_train, y_train, model__validation_split=0.2)\n",
    "pipe_3.fit(x_train, y_train, model__validation_split=0.2)\n",
    "pipe_4.fit(x_train, y_train, model__validation_split=0.2)\n",
    "\n",
    "print('pipeline completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d8d33daf-7fc9-467b-ab15-00f6e195775a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN Metrics:\n",
      "  MSE: 1.1252588081922852\n",
      "  MASE: 0.793344423647188\n",
      "  RMSE: 1.0607821681157188\n",
      "  R-squared: -0.06233056799849257\n",
      "RNN Metrics:\n",
      "  MSE: 1.12076811655544\n",
      "  MASE: 0.7893657525734016\n",
      "  RMSE: 1.0586633631874864\n",
      "  R-squared: -0.068889783542309\n",
      "LSTM Metrics:\n",
      "  MSE: 1.1049960433796273\n",
      "  MASE: 0.7843311443722112\n",
      "  RMSE: 1.051187920107355\n",
      "  R-squared: -0.0604281530201431\n",
      "GRU Metrics:\n",
      "  MSE: 1.1244375898126866\n",
      "  MASE: 0.7932428573250438\n",
      "  RMSE: 1.060395015931651\n",
      "  R-squared: -0.061995264495718905\n"
     ]
    }
   ],
   "source": [
    "# Evaluation (Enhanced)\n",
    "for pipe, model_name in zip([pipe_1, pipe_2, pipe_3, pipe_4], \n",
    "                            [\"ANN\", \"RNN\", \"LSTM\", \"GRU\"]):\n",
    "    y_pred = pipe.predict(x_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mase = mean_absolute_scaled_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"{model_name} Metrics:\")\n",
    "    print(\"  MSE:\", mse)\n",
    "    print(\"  MASE:\", mase)\n",
    "    print(\"  RMSE:\", rmse)\n",
    "    print(\"  R-squared:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7d4692d3-d27d-42b0-8177-84cb0f6c2285",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 데이터 변환 \n",
    "X_train = x_train.reshape((-1, 1, 6))\n",
    "X_test = x_test.reshape((-1, 1, 6))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-tensorflow-tensorflow",
   "name": "workbench-notebooks.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m123"
  },
  "kernelspec": {
   "display_name": "TensorFlow 2-11 (Local)",
   "language": "python",
   "name": "conda-env-tensorflow-tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
