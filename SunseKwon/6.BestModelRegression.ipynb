{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d2e7dad-6b68-47bd-9b23-eb3f6c5edbf5",
   "metadata": {},
   "source": [
    "# Best Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa1d67a4-24eb-4e5a-b6e3-a34a21666232",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 01:07:15.854465: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-08 01:07:16.053824: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-08 01:07:16.087117: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-08-08 01:07:16.087131: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-08-08 01:07:16.895503: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-08-08 01:07:16.895711: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-08-08 01:07:16.895717: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f915659-6f3c-42d7-89f4-f89d0bb4bd6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5a21859-01ce-4227-b06a-43c8d1739004",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c6ddcfd-931d-4298-beb4-8e55fa5a2fc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MASE\n",
    "def mean_absolute_scaled_error(y_true, y_pred):\n",
    "    n = len(y_true)\n",
    "\n",
    "    # Calculate MAE of the forecasts\n",
    "    mae_forecast = np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "    # Calculate MAE of the naive forecast\n",
    "    mae_naive = np.mean(np.abs(np.diff(y_true)))  # Diff calculates y_i - y_{i-1}\n",
    "\n",
    "    # Ensure denominator is not zero\n",
    "    if mae_naive == 0:\n",
    "        return np.inf  # Return infinity if naive MAE is zero\n",
    "\n",
    "    return mae_forecast / mae_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e67ddac1-3f83-454e-a6ae-6ba00dc150ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merge_B_ip = pd.read_csv('./data/merge_B_ip.csv', encoding = 'cp949')\n",
    "merge_C_ip = pd.read_csv('./data/merge_C_ip.csv', encoding = 'cp949')\n",
    "merge_D_ip = pd.read_csv('./data/merge_D_ip.csv', encoding = 'cp949')\n",
    "merge_E_ip = pd.read_csv('./data/merge_E_ip.csv', encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4a27985-6102-4700-b901-ab83c90e7fe0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_merged = pd.concat([merge_B_ip,merge_C_ip,merge_D_ip,merge_E_ip])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6bdaed3-ea1e-46ba-93a5-f760bfba1824",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = ['Stem Diameter', 'Petiole Length','Leaf Count', 'Leaf Length', 'Leaf Width', 'Fruit Count',\n",
    "       'Plant Height', 'Final Inflorescence Order','Inflorescence Flower Count', 'supplyEC', 'supplyPH', 'innerCO2',\n",
    "       'innerHum', 'innerTemp', 'innerSolar', 'Survey Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08b72953-459c-4bfc-a208-4791295dbbf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_merged = df_merged[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7503e789-dc87-4dbc-86aa-8de3edeb3733",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_merged['Survey Date'] = pd.to_datetime(df_merged['Survey Date'], format='%Y-%m-%d %H:%M')\n",
    "df_merged.set_index('Survey Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4b56213-bf6b-4d1f-b681-e76f63355cde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_merged.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e98a6cc-ec36-4d94-996f-5a4e732db398",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 171897 entries, 2023-10-06 00:00:00 to 2024-04-26 00:00:00\n",
      "Data columns (total 15 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   Stem Diameter               171897 non-null  float64\n",
      " 1   Petiole Length              171897 non-null  float64\n",
      " 2   Leaf Count                  171897 non-null  float64\n",
      " 3   Leaf Length                 171897 non-null  float64\n",
      " 4   Leaf Width                  171897 non-null  float64\n",
      " 5   Fruit Count                 171897 non-null  int64  \n",
      " 6   Plant Height                171897 non-null  float64\n",
      " 7   Final Inflorescence Order   171897 non-null  int64  \n",
      " 8   Inflorescence Flower Count  171897 non-null  int64  \n",
      " 9   supplyEC                    171897 non-null  float64\n",
      " 10  supplyPH                    171897 non-null  float64\n",
      " 11  innerCO2                    171897 non-null  float64\n",
      " 12  innerHum                    171897 non-null  float64\n",
      " 13  innerTemp                   171897 non-null  float64\n",
      " 14  innerSolar                  171897 non-null  float64\n",
      "dtypes: float64(12), int64(3)\n",
      "memory usage: 21.0 MB\n"
     ]
    }
   ],
   "source": [
    "df_merged.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77275b20-1475-4be2-9ba0-4d1534e5b28a",
   "metadata": {},
   "source": [
    "## train, validation, test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52a066f0-4c7b-4c96-90ff-b50591c00679",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(df_merged, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e3c3cb-7cf1-4f55-85dd-e1e2dbdc5441",
   "metadata": {},
   "source": [
    "## normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "697d6dfb-58cc-4741-a442-2c6171eae183",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train = scaler.fit_transform(train)\n",
    "test = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d649d8f8-fc72-4dcf-880c-01c9ee067f23",
   "metadata": {},
   "source": [
    "## x,y split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d345760f-007f-46ba-9404-7a366d353100",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((137517, 15), (34380, 15))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29d8c060-631c-4244-a44b-fc0715af486c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = train[:,9:]\n",
    "y_train = train[:,:9]\n",
    "x_test = test[:,9:]\n",
    "y_test = test[:,:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69deeee2-f514-4fe5-9a85-6f1f36ec317f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((137517, 6), (137517, 9))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ea0935d-3769-4424-b278-b4ce2889ad11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((34380, 6), (34380, 9))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1aefa6a-ce34-461b-a7ed-5ed254215de5",
   "metadata": {},
   "source": [
    "## best model selection (Machine Learning Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffd925fd-cfda-4940-8cc3-c252d66ff5e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LinearRegression': LinearRegression(fit_intercept=False),\n",
    "    'RandomForestRegressor': RandomForestRegressor(n_estimators=278, min_samples_split=3, min_samples_leaf=7, max_features=\"sqrt\", max_depth=21, bootstrap=True),\n",
    "    'BaggingRegressor': BaggingRegressor(n_estimators=500,max_samples=1.0,max_features=1.0,bootstrap_features=True,bootstrap=False),\n",
    "    'XGBoostRegressor': XGBRegressor(n_estimators=500,objective=\"reg:squarederror\",subsample=1.0,max_depth=6,learning_rate=0.09176042457246529,colsample_bytree=0.9),\n",
    "    'ElasticNetRegressor': ElasticNet(tol=0.07427333578580918, max_iter=5804,l1_ratio=0.1008807639223882,fit_intercept=True,alpha=\n",
    "1.1162875572947195e-05),\n",
    "    'KNNRegressor': KNeighborsRegressor(weights=\"distance\", p=2,n_neighbors=17,leaf_size=12,algorithm=\"ball_tree\")\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d847a350-3d05-4df5-85c9-4e2161c2249a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression - MSE: 1.167496946890475\n",
      "LinearRegression - MASE: 0.8037111005905347\n",
      "LinearRegression - R2: -0.07158540449219493\n",
      "LinearRegression - RMSE: 1.0805077264371945\n",
      "LinearRegression - TrainingTime: 0.04133129119873047\n",
      "Model saved as ./save_models_all/LinearRegression_model.h5\n",
      "RandomForestRegressor - MSE: 0.7051196035196152\n",
      "RandomForestRegressor - MASE: 0.596625038082696\n",
      "RandomForestRegressor - R2: 0.2730233142003069\n",
      "RandomForestRegressor - RMSE: 0.8397140010263109\n",
      "RandomForestRegressor - TrainingTime: 68.46667718887329\n",
      "Model saved as ./save_models_all/RandomForestRegressor_model.h5\n",
      "BaggingRegressor - MSE: 0.8331340870193027\n",
      "BaggingRegressor - MASE: 0.5892370046434061\n",
      "BaggingRegressor - R2: 0.08201124970787269\n",
      "BaggingRegressor - RMSE: 0.9127617909505759\n",
      "BaggingRegressor - TrainingTime: 433.8897638320923\n",
      "Model saved as ./save_models_all/BaggingRegressor_model.h5\n",
      "XGBoostRegressor - MSE: 0.7843725884591342\n",
      "XGBoostRegressor - MASE: 0.6352296251834003\n",
      "XGBoostRegressor - R2: 0.19219429769638194\n",
      "XGBoostRegressor - RMSE: 0.8856481177415408\n",
      "XGBoostRegressor - TrainingTime: 21.2800612449646\n",
      "Model saved as ./save_models_all/XGBoostRegressor_model.h5\n",
      "ElasticNetRegressor - MSE: 1.167497400633889\n",
      "ElasticNetRegressor - MASE: 0.8037114676097002\n",
      "ElasticNetRegressor - R2: -0.07158577619184496\n",
      "ElasticNetRegressor - RMSE: 1.08050793640486\n",
      "ElasticNetRegressor - TrainingTime: 0.07814526557922363\n",
      "Model saved as ./save_models_all/ElasticNetRegressor_model.h5\n",
      "KNNRegressor - MSE: 0.855925365291738\n",
      "KNNRegressor - MASE: 0.5938650380499926\n",
      "KNNRegressor - R2: 0.05606189081237361\n",
      "KNNRegressor - RMSE: 0.9251623453706588\n",
      "KNNRegressor - TrainingTime: 0.1812756061553955\n",
      "Model saved as ./save_models_all/KNNRegressor_model.h5\n",
      "                   Model       MSE      MASE        R2      RMSE  TrainingTime\n",
      "0       LinearRegression  1.167497  0.803711 -0.071585  1.080508      0.041331\n",
      "1  RandomForestRegressor  0.705120  0.596625  0.273023  0.839714     68.466677\n",
      "2       BaggingRegressor  0.833134  0.589237  0.082011  0.912762    433.889764\n",
      "3       XGBoostRegressor  0.784373  0.635230  0.192194  0.885648     21.280061\n",
      "4    ElasticNetRegressor  1.167497  0.803711 -0.071586  1.080508      0.078145\n",
      "5           KNNRegressor  0.855925  0.593865  0.056062  0.925162      0.181276\n"
     ]
    }
   ],
   "source": [
    "# MLflow Tracking Setup\n",
    "mlflow.set_tracking_uri(\"https://spacefarm:coolguyisyou@mlflow-izqyq2ng5q-du.a.run.app\")\n",
    "mlflow.set_experiment(\"ML_model_comparison\")\n",
    "\n",
    "# Dictionary to store the performance metrics for each model\n",
    "metrics = {\n",
    "    'Model': [],\n",
    "    'MSE': [],\n",
    "    'MASE': [],\n",
    "    'R2': [],\n",
    "    'RMSE': [],\n",
    "    'TrainingTime': []\n",
    "}\n",
    "\n",
    "# Directory to save model weights\n",
    "save_model_path = './save_models_all'\n",
    "os.makedirs(save_model_path, exist_ok=True)  # Create the directory if it does not exist\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    with mlflow.start_run(run_name=name):\n",
    "        # Record the start time\n",
    "        start_time = time.time()\n",
    "    \n",
    "        # Fit the model\n",
    "        model.fit(x_train, y_train)\n",
    "    \n",
    "        # Record the end time\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Calculate training time\n",
    "        training_time = end_time - start_time\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = model.predict(x_test)\n",
    "\n",
    "        # Calculate performance metrics\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mase = mean_absolute_scaled_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        \n",
    "        # Log parameters to MLflow\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        # Log metrics to MLflow\n",
    "        mlflow.log_metrics({\n",
    "            \"mse\": mse,\n",
    "            \"rmse\": rmse,\n",
    "            \"r2\": r2,\n",
    "            \"mase\": mase,\n",
    "            \"training_time\": training_time\n",
    "        })\n",
    "\n",
    "        # Store the metrics\n",
    "        metrics['Model'].append(name)\n",
    "        metrics['MSE'].append(mse)\n",
    "        metrics['MASE'].append(mase)\n",
    "        metrics['R2'].append(r2)\n",
    "        metrics['RMSE'].append(rmse)\n",
    "        metrics['TrainingTime'].append(training_time)\n",
    "        \n",
    "        # Save the model using MLflow\n",
    "        mlflow.sklearn.log_model(model, artifact_path=\"models\")\n",
    "\n",
    "        # Print metrics to console\n",
    "        print(f'{name} - MSE: {mse:.4f}, RMSE: {rmse:.4f}, R2: {r2:.4f}, MASE: {mase:.4f}, Training Time: {training_time:.2f} seconds')\n",
    "        \n",
    "\n",
    "# Convert the metrics dictionary to a DataFrame for a cleaner display\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "print(metrics_df)\n",
    "\n",
    "# Save the metrics to a CSV file\n",
    "metrics_df.to_csv('result_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "37834eb0-043b-41a0-b089-d410d160a010",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137517, 6)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93f3517-2594-44fe-8504-8463063ef8c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## baseline model selection (deep learning models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8c88dee9-a57b-4670-837e-2edcb2e71596",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline completed\n"
     ]
    }
   ],
   "source": [
    "# 1. Model Definitions (with EarlyStopping)\n",
    "def create_model_1():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(100, activation='tanh', input_shape=(x_train.shape[1],)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(100, activation='tanh'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(100, activation='tanh'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(y_train.shape[1])\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mse')\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    return model, early_stopping  # Return both the model and the callback\n",
    "\n",
    "def create_model_2():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.SimpleRNN(100, activation='tanh', return_sequences=True),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.SimpleRNN(100, activation='tanh'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(y_train.shape[1])\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mse')\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    return model, early_stopping\n",
    "\n",
    "def create_model_3():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(100, activation='tanh', return_sequences=True),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.LSTM(100, activation='tanh'),\n",
    "        tf.keras.layers.Dense(100, activation='sigmoid'), \n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(y_train.shape[1])  \n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mse')\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    return model, early_stopping\n",
    "\n",
    "def create_model_4():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.GRU(100, activation='tanh', return_sequences=True),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.GRU(100, activation='tanh'),\n",
    "        tf.keras.layers.Dense(100, activation='sigmoid'), \n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(y_train.shape[1])  \n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mse')\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    return model, early_stopping\n",
    "\n",
    "\n",
    "def reshape_for_rnn(X):\n",
    "    # Assuming X has shape (num_samples, num_features) for ANN\n",
    "    num_samples = X.shape[0]\n",
    "    time_steps = 1  # If each sample is a single time step\n",
    "    num_features = X.shape[1]\n",
    "    return X.reshape(num_samples, time_steps, num_features)\n",
    "\n",
    "\n",
    "# Create KerasRegressor Objects\n",
    "model_1, early_stopping_1 = create_model_1()\n",
    "model_1_regressor = KerasRegressor(\n",
    "    build_fn=lambda: model_1,  epochs=100,  batch_size=32, verbose=0, callbacks=[early_stopping_1] \n",
    ")\n",
    "\n",
    "model_2, early_stopping_2 = create_model_2()\n",
    "model_2_regressor = KerasRegressor(\n",
    "    build_fn=lambda: model_2, epochs=100, batch_size=32, verbose=0, callbacks=[early_stopping_2]\n",
    ")\n",
    "\n",
    "model_3, early_stopping_3 = create_model_3()\n",
    "model_3_regressor = KerasRegressor(\n",
    "    build_fn=lambda: model_3, epochs=100, batch_size=32, verbose=0, callbacks=[early_stopping_3]\n",
    ")\n",
    "\n",
    "model_4, early_stopping_4 = create_model_4()\n",
    "model_4_regressor = KerasRegressor(\n",
    "    build_fn=lambda: model_4, epochs=100, batch_size=32, verbose=0, callbacks=[early_stopping_4]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Pipeline (Updated)\n",
    "pipe_1 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', model_1_regressor)\n",
    "])\n",
    "\n",
    "    \n",
    "pipe_2 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('reshape', FunctionTransformer(reshape_for_rnn)),  # Add reshaping step\n",
    "    ('model', model_2_regressor)\n",
    "])\n",
    "\n",
    "pipe_3 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('reshape', FunctionTransformer(reshape_for_rnn)), \n",
    "    ('model', model_3_regressor)\n",
    "])\n",
    "\n",
    "pipe_4 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('reshape', FunctionTransformer(reshape_for_rnn)), \n",
    "    ('model', model_4_regressor)\n",
    "])\n",
    "\n",
    "\n",
    "print('pipeline completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2c0bb05f-c3bd-44d6-9534-9921fdcf4944",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dictionary to store the performance metrics for each model\n",
    "metrics = {\n",
    "    'Model': [],\n",
    "    'MSE': [],\n",
    "    'MASE': [],\n",
    "    'R2': [],\n",
    "    'RMSE': [],\n",
    "    'TrainingTime': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d8d33daf-7fc9-467b-ab15-00f6e195775a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN Metrics:\n",
      "  MSE: 1.1208458595037782\n",
      "  MASE: 0.7913080801793806\n",
      "  RMSE: 1.0587000800527873\n",
      "  R-squared: -0.05511522645115138\n",
      "KNNRegressor - TrainingTime: 78.44186568260193\n",
      "RNN Metrics:\n",
      "  MSE: 1.1385370133781725\n",
      "  MASE: 0.7989043728513088\n",
      "  RMSE: 1.0670224990027963\n",
      "  R-squared: -0.07600072034588072\n",
      "KNNRegressor - TrainingTime: 109.32416939735413\n",
      "LSTM Metrics:\n",
      "  MSE: 1.1124911297043947\n",
      "  MASE: 0.7880598289018206\n",
      "  RMSE: 1.0547469505546792\n",
      "  R-squared: -0.052284700872649664\n",
      "KNNRegressor - TrainingTime: 104.88369822502136\n",
      "GRU Metrics:\n",
      "  MSE: 1.1298594894385028\n",
      "  MASE: 0.7926577396418715\n",
      "  RMSE: 1.0629484886101033\n",
      "  R-squared: -0.06514989035315918\n",
      "KNNRegressor - TrainingTime: 101.07052063941956\n",
      "  Model       MSE      MASE        R2      RMSE  TrainingTime\n",
      "0   ANN  1.120846  0.791308 -0.055115  1.058700     78.441866\n",
      "1   RNN  1.138537  0.798904 -0.076001  1.067022    109.324169\n",
      "2  LSTM  1.112491  0.788060 -0.052285  1.054747    104.883698\n",
      "3   GRU  1.129859  0.792658 -0.065150  1.062948    101.070521\n"
     ]
    }
   ],
   "source": [
    "# Evaluation (Enhanced)\n",
    "for pipe, model_name in zip([pipe_1, pipe_2, pipe_3, pipe_4], \n",
    "                            [\"ANN\", \"RNN\", \"LSTM\", \"GRU\"]):\n",
    "    # Record the start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    pipe.fit(x_train, y_train, model__validation_split=0.2)  \n",
    "    \n",
    "    # Record the end time\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Calculate training time\n",
    "    training_time = end_time - start_time\n",
    "    \n",
    "    y_pred = pipe.predict(x_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mase = mean_absolute_scaled_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    \n",
    "    # Store the metrics\n",
    "    metrics['Model'].append(model_name)\n",
    "    metrics['MSE'].append(mse)\n",
    "    metrics['MASE'].append(mase)\n",
    "    metrics['R2'].append(r2)\n",
    "    metrics['RMSE'].append(rmse)\n",
    "    metrics['TrainingTime'].append(training_time)\n",
    "    \n",
    "    \n",
    "    print(f\"{model_name} Metrics:\")\n",
    "    print(\"  MSE:\", mse)\n",
    "    print(\"  MASE:\", mase)\n",
    "    print(\"  RMSE:\", rmse)\n",
    "    print(\"  R-squared:\", r2)\n",
    "    print(f'{model_name} - TrainingTime: {training_time}')\n",
    "    \n",
    "    \n",
    "# Convert the metrics dictionary to a DataFrame for a cleaner display\n",
    "metrics_deep_learning = pd.DataFrame(metrics)\n",
    "print(metrics_deep_learning)\n",
    "\n",
    "# Save the metrics to a CSV file\n",
    "metrics_deep_learning.to_csv('result_deep_learning.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7d4692d3-d27d-42b0-8177-84cb0f6c2285",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 데이터 변환 \n",
    "X_train = x_train.reshape((-1, 1, 6))\n",
    "X_test = x_test.reshape((-1, 1, 6))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-tensorflow-tensorflow",
   "name": "workbench-notebooks.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m123"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
