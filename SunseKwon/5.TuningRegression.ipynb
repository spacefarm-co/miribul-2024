{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "36c0cb5e-d103-44e2-8516-7f3c7a720be5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import mlflow\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, GRU, Dense, Dropout, Layer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV, KFold, cross_val_predict  \n",
    "import optuna\n",
    "from optuna.integration import MLflowCallback\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbfa199b-4580-4b71-b1be-2ed085acd6b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a7ee214-2b54-4890-9460-ee443eae534c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a36942b5-d9d7-4a8d-b198-5ac2e2c194fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MASE\n",
    "def mean_absolute_scaled_error(y_true, y_pred):\n",
    "    n = len(y_true)\n",
    "\n",
    "    # Calculate MAE of the forecasts\n",
    "    mae_forecast = np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "    # Calculate MAE of the naive forecast\n",
    "    mae_naive = np.mean(np.abs(np.diff(y_true)))  # Diff calculates y_i - y_{i-1}\n",
    "\n",
    "    # Ensure denominator is not zero\n",
    "    if mae_naive == 0:\n",
    "        return np.inf  # Return infinity if naive MAE is zero\n",
    "\n",
    "    return mae_forecast / mae_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81f67e8c-616a-4d23-9fa7-e6369632255d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merge_B_ip = pd.read_csv('./data/merge_B_ip.csv', encoding = 'cp949')\n",
    "merge_C_ip = pd.read_csv('./data/merge_C_ip.csv', encoding = 'cp949')\n",
    "merge_D_ip = pd.read_csv('./data/merge_D_ip.csv', encoding = 'cp949')\n",
    "merge_E_ip = pd.read_csv('./data/merge_E_ip.csv', encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4870a73-c520-470d-982d-72e7ab65cf00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_merged = pd.concat([merge_B_ip,merge_C_ip,merge_D_ip,merge_E_ip])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd2b0e07-9849-4ceb-a25e-6a8ddd3d26fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = ['Stem Diameter', 'Petiole Length','Leaf Count', 'Leaf Length', 'Leaf Width', 'Fruit Count',\n",
    "       'Plant Height', 'Final Inflorescence Order','Inflorescence Flower Count', 'supplyEC', 'supplyPH', 'innerCO2',\n",
    "       'innerHum', 'innerTemp', 'innerSolar', 'Survey Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4b04a59-bc10-4c1b-86a9-75259d864179",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_merged = df_merged[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "445e8f83-fb77-4b8f-b799-dedccd022974",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_merged['Survey Date'] = pd.to_datetime(df_merged['Survey Date'], format='%Y-%m-%d %H:%M')\n",
    "df_merged.set_index('Survey Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e835b03c-5c9c-44fd-a5b8-335aacbf9461",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_merged.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c316a656-4a0a-4931-987a-3ec9c29518ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 171897 entries, 2023-10-06 00:00:00 to 2024-04-26 00:00:00\n",
      "Data columns (total 15 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   Stem Diameter               171897 non-null  float64\n",
      " 1   Petiole Length              171897 non-null  float64\n",
      " 2   Leaf Count                  171897 non-null  float64\n",
      " 3   Leaf Length                 171897 non-null  float64\n",
      " 4   Leaf Width                  171897 non-null  float64\n",
      " 5   Fruit Count                 171897 non-null  int64  \n",
      " 6   Plant Height                171897 non-null  float64\n",
      " 7   Final Inflorescence Order   171897 non-null  int64  \n",
      " 8   Inflorescence Flower Count  171897 non-null  int64  \n",
      " 9   supplyEC                    171897 non-null  float64\n",
      " 10  supplyPH                    171897 non-null  float64\n",
      " 11  innerCO2                    171897 non-null  float64\n",
      " 12  innerHum                    171897 non-null  float64\n",
      " 13  innerTemp                   171897 non-null  float64\n",
      " 14  innerSolar                  171897 non-null  float64\n",
      "dtypes: float64(12), int64(3)\n",
      "memory usage: 21.0 MB\n"
     ]
    }
   ],
   "source": [
    "df_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad25fd03-71e0-4b38-a18d-b72e40ede517",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Train, test = train_test_split(df_merged, test_size=0.2, shuffle=False)\n",
    "train, val = train_test_split(Train, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40f6f98d-ead5-4bcd-9cb7-f0aab30110c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "s_train = scaler.fit_transform(train)\n",
    "s_val = scaler.transform(val)\n",
    "s_test = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a9e17bf-7cd0-41ad-98e1-7ad4423d2aa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = s_train[:,9:]\n",
    "y_train = s_train[:,:9]\n",
    "\n",
    "x_val = s_val[:,9:]\n",
    "y_val = s_val[:,:9]\n",
    "\n",
    "x_test = s_test[:,9:]\n",
    "y_test = s_test[:,:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15b31dbe-7169-48b1-a32b-fd1f2454948f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tuning machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6c6e067-8cdb-416d-b162-ceac0658d88b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bagging regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0270f4fd-6df4-4f51-910c-a1ffe76c3348",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"https://spacefarm:coolguyisyou@mlflow-izqyq2ng5q-du.a.run.app\")\n",
    "mlflow.set_experiment(\"bagging_regressor_tuning\")  # Changed experiment name\n",
    "\n",
    "# Define objective function\n",
    "def objective(trial):\n",
    "    with mlflow.start_run(run_name=f\"trial_{trial.number}\"):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_categorical('n_estimators', [100, 200, 500]),\n",
    "            'max_samples': trial.suggest_categorical('max_samples', [0.5, 0.8, 1.0]),\n",
    "            'max_features': trial.suggest_categorical('max_features', [0.5, 0.8, 1.0]),\n",
    "            'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n",
    "            'bootstrap_features': trial.suggest_categorical('bootstrap_features', [True, False])\n",
    "        }\n",
    "\n",
    "        model = BaggingRegressor(**params)  # Changed model type\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_val)\n",
    "\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        mase = mean_absolute_scaled_error(y_val, y_pred)\n",
    "        rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "        r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "        # Log params and metrics to MLflow\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metrics({\n",
    "                    \"mse\": mse,\n",
    "                    \"rmse\": rmse,\n",
    "                    \"r2\": r2,\n",
    "                    \"mase\": mase\n",
    "        })\n",
    "\n",
    "    return rmse\n",
    "\n",
    "# Optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=10)  # Adjust n_trials as needed\n",
    "\n",
    "# Print best parameters and score\n",
    "print('Best parameters:', study.best_params)\n",
    "print('Best RMSE:', study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def698bb-859c-4437-8301-4ce0a2e85b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2d1082e-cc36-477e-8fea-2a45d34ff8d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 20:58:45,667] A new study created in memory with name: no-name-d1910b8a-30a0-4b9c-ba7b-d21f6041aa90\n",
      "[I 2024-08-07 20:58:49,708] Trial 0 finished with value: 0.9093586004477778 and parameters: {'n_estimators': 500, 'learning_rate': 0.018745163411569697, 'max_depth': 4, 'subsample': 0.9, 'colsample_bytree': 1.0}. Best is trial 0 with value: 0.9093586004477778.\n",
      "[I 2024-08-07 20:59:01,544] Trial 1 finished with value: 0.8915818793144648 and parameters: {'n_estimators': 1000, 'learning_rate': 0.013425436179249163, 'max_depth': 5, 'subsample': 0.8, 'colsample_bytree': 0.9}. Best is trial 1 with value: 0.8915818793144648.\n",
      "[I 2024-08-07 20:59:14,404] Trial 2 finished with value: 0.8571479519738282 and parameters: {'n_estimators': 1000, 'learning_rate': 0.08812296435661437, 'max_depth': 5, 'subsample': 0.9, 'colsample_bytree': 0.9}. Best is trial 2 with value: 0.8571479519738282.\n",
      "[I 2024-08-07 20:59:16,521] Trial 3 finished with value: 0.9178081219154502 and parameters: {'n_estimators': 200, 'learning_rate': 0.0168789118784606, 'max_depth': 3, 'subsample': 1.0, 'colsample_bytree': 1.0}. Best is trial 2 with value: 0.8571479519738282.\n",
      "[I 2024-08-07 20:59:17,559] Trial 4 finished with value: 0.9170314219240948 and parameters: {'n_estimators': 100, 'learning_rate': 0.08593752783669191, 'max_depth': 3, 'subsample': 0.9, 'colsample_bytree': 1.0}. Best is trial 2 with value: 0.8571479519738282.\n",
      "[I 2024-08-07 20:59:26,206] Trial 5 finished with value: 0.9145513990537568 and parameters: {'n_estimators': 1000, 'learning_rate': 0.013380611626888944, 'max_depth': 3, 'subsample': 0.8, 'colsample_bytree': 1.0}. Best is trial 2 with value: 0.8571479519738282.\n",
      "[I 2024-08-07 20:59:30,167] Trial 6 finished with value: 0.8858469134542848 and parameters: {'n_estimators': 200, 'learning_rate': 0.021970239811666507, 'max_depth': 7, 'subsample': 1.0, 'colsample_bytree': 1.0}. Best is trial 2 with value: 0.8571479519738282.\n",
      "[I 2024-08-07 20:59:41,706] Trial 7 finished with value: 0.8820374711979843 and parameters: {'n_estimators': 1000, 'learning_rate': 0.032489720482822, 'max_depth': 5, 'subsample': 1.0, 'colsample_bytree': 1.0}. Best is trial 2 with value: 0.8571479519738282.\n",
      "[I 2024-08-07 20:59:43,901] Trial 8 finished with value: 0.9137004604342365 and parameters: {'n_estimators': 100, 'learning_rate': 0.019726450586685165, 'max_depth': 5, 'subsample': 0.8, 'colsample_bytree': 0.8}. Best is trial 2 with value: 0.8571479519738282.\n",
      "[I 2024-08-07 20:59:54,140] Trial 9 finished with value: 0.8924991136471482 and parameters: {'n_estimators': 500, 'learning_rate': 0.010195566186678601, 'max_depth': 6, 'subsample': 0.9, 'colsample_bytree': 0.8}. Best is trial 2 with value: 0.8571479519738282.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 1000, 'learning_rate': 0.08812296435661437, 'max_depth': 5, 'subsample': 0.9, 'colsample_bytree': 0.9}\n",
      "Best RMSE: 0.8571479519738282\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"https://spacefarm:coolguyisyou@mlflow-izqyq2ng5q-du.a.run.app\") \n",
    "mlflow.set_experiment(\"xgboost_tuning1\")\n",
    "\n",
    "# Define objective function\n",
    "def objective(trial):\n",
    "    with mlflow.start_run(run_name=f\"trial_{trial.number}\"):\n",
    "        params = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'n_estimators': trial.suggest_categorical('n_estimators', [100, 200, 500, 1000]),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 7),\n",
    "        'subsample': trial.suggest_categorical('subsample', [0.8, 0.9, 1.0]),\n",
    "        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.8, 0.9, 1.0])\n",
    "        }\n",
    "        model = xgb.XGBRegressor(**params)\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_val)\n",
    "\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        mase = mean_absolute_scaled_error(y_val, y_pred)\n",
    "        rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "        r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "        # Log params and metrics to MLflow\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metrics({\n",
    "                    \"mse\": mse,\n",
    "                    \"rmse\": rmse,\n",
    "                    \"r2\": r2,\n",
    "                    \"mase\": mase\n",
    "        })\n",
    "\n",
    "    return rmse\n",
    "\n",
    "# Optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=10)  # Adjust n_trials based on your time/resource constraints\n",
    "\n",
    "# Print best parameters and score\n",
    "print('Best parameters:', study.best_params)\n",
    "print('Best RMSE:', study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0f93bd-81eb-41ca-93d6-4972f7018406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8caaa0-2117-4315-8ad8-e440726d29b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"https://spacefarm:coolguyisyou@mlflow-izqyq2ng5q-du.a.run.app\")\n",
    "mlflow.set_experiment(\"linear_regression_tuning\")  # Updated experiment name\n",
    "\n",
    "# Define objective function\n",
    "def objective(trial):\n",
    "    with mlflow.start_run(run_name=f\"trial_{trial.number}\"):\n",
    "        params = {\n",
    "            'fit_intercept': trial.suggest_categorical('fit_intercept', [True, False]),\n",
    "            # 'alpha': trial.suggest_float('alpha', 1e-5, 1e2, log=True), \n",
    "            # 'l1_ratio': trial.suggest_float('l1_ratio', 0, 1),          # Lasso (L1) or ElasticNet (L1 + L2) - uncomment if using ElasticNet\n",
    "            # 'normalize': trial.suggest_categorical('normalize', [True, False])\n",
    "        }\n",
    "\n",
    "        model = LinearRegression(**params)\n",
    "        model.fit(x_train, y_train)  # Replace x_train, y_train with your data\n",
    "        y_pred = model.predict(x_val)    # Replace x_val with your data\n",
    "\n",
    "        # Evaluate using MSE\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "        mase = mean_absolute_scaled_error(y_val, y_pred)\n",
    "        r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "        # Log params and metrics to MLflow\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metrics({\n",
    "            \"mse\": mse,\n",
    "            \"rmse\": rmse,\n",
    "            \"mase\": mase,\n",
    "            \"r2\": r2\n",
    "        })\n",
    "        \n",
    "        # Use RMSE as the optimization target\n",
    "        return rmse  \n",
    "\n",
    "# Optimize\n",
    "study = optuna.create_study(direction='minimize')  # Minimize RMSE\n",
    "study.optimize(objective, n_trials=10)  # Adjust n_trials as needed\n",
    "\n",
    "# Print best parameters and score\n",
    "print('Best parameters:', study.best_params)\n",
    "print('Best RMSE:', study.best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe2f8fa-89a0-427f-afaf-2307f2252af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# elasticnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6ffb9e-2865-4696-a747-0c3cc7e9883a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"https://spacefarm:coolguyisyou@mlflow-izqyq2ng5q-du.a.run.app\")\n",
    "mlflow.set_experiment(\"elasticnet_tuning\")  # Updated experiment name\n",
    "\n",
    "# Define objective function\n",
    "def objective(trial):\n",
    "    with mlflow.start_run(run_name=f\"trial_{trial.number}\"):\n",
    "        params = {\n",
    "            'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e2),\n",
    "            'l1_ratio': trial.suggest_float('l1_ratio', 0.0, 1.0),\n",
    "            'fit_intercept': trial.suggest_categorical('fit_intercept', [True, False]),\n",
    "            # 'normalize': trial.suggest_categorical('normalize', [True, False]), # If your features are not standardized\n",
    "            'max_iter': trial.suggest_int('max_iter', 100, 10000),\n",
    "            'tol': trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
    "        }\n",
    "\n",
    "        model = ElasticNet(**params)\n",
    "        model.fit(x_train, y_train)  \n",
    "        y_pred = model.predict(x_val)    \n",
    "\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "        mase = mean_absolute_scaled_error(y_val, y_pred)\n",
    "        r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "        # Log params and metrics to MLflow\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metrics({\n",
    "            \"mse\": mse,\n",
    "            \"rmse\": rmse,\n",
    "            \"mase\": mase,\n",
    "            \"r2\": r2\n",
    "        })\n",
    "        \n",
    "        # Use RMSE as the optimization target\n",
    "        return rmse  \n",
    "\n",
    "# Optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=10)  # Adjust n_trials as needed\n",
    "\n",
    "# Print best parameters and score\n",
    "print('Best parameters:', study.best_params)\n",
    "print('Best RMSE:', study.best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eb7018-b5d8-4ba0-8f37-5601d4f801b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomforest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbaed2f1-a1cb-436c-96bc-aaef1232ffe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/07 21:35:31 INFO mlflow.tracking.fluent: Experiment with name 'randomforest_regressor_tuning' does not exist. Creating a new experiment.\n",
      "[I 2024-08-07 21:35:31,262] A new study created in memory with name: no-name-5b226e9a-56cc-4308-8e40-890cd6397b93\n",
      "[I 2024-08-07 21:35:36,975] Trial 0 finished with value: 0.9197814981982376 and parameters: {'n_estimators': 158, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 0 with value: 0.9197814981982376.\n",
      "[I 2024-08-07 21:36:12,691] Trial 1 finished with value: 0.8699257446120847 and parameters: {'n_estimators': 386, 'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 1 with value: 0.8699257446120847.\n",
      "[I 2024-08-07 21:36:28,418] Trial 2 finished with value: 0.9418069185335862 and parameters: {'n_estimators': 199, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 5, 'max_features': 'auto', 'bootstrap': True}. Best is trial 1 with value: 0.8699257446120847.\n",
      "[I 2024-08-07 21:36:52,632] Trial 3 finished with value: 0.8091133437973721 and parameters: {'n_estimators': 278, 'max_depth': 21, 'min_samples_split': 3, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 3 with value: 0.8091133437973721.\n",
      "[I 2024-08-07 21:37:10,942] Trial 4 finished with value: 0.9327237769561538 and parameters: {'n_estimators': 276, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 8, 'max_features': 'auto', 'bootstrap': True}. Best is trial 3 with value: 0.8091133437973721.\n",
      "[I 2024-08-07 21:38:26,221] Trial 5 finished with value: 0.838147360854876 and parameters: {'n_estimators': 424, 'max_depth': 17, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'auto', 'bootstrap': True}. Best is trial 3 with value: 0.8091133437973721.\n",
      "[I 2024-08-07 21:38:33,749] Trial 6 finished with value: 0.9327120536396694 and parameters: {'n_estimators': 207, 'max_depth': 2, 'min_samples_split': 9, 'min_samples_leaf': 7, 'max_features': 'auto', 'bootstrap': True}. Best is trial 3 with value: 0.8091133437973721.\n",
      "[I 2024-08-07 21:38:51,833] Trial 7 finished with value: 0.9291792599140604 and parameters: {'n_estimators': 364, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 7, 'max_features': 'auto', 'bootstrap': True}. Best is trial 3 with value: 0.8091133437973721.\n",
      "[I 2024-08-07 21:38:55,702] Trial 8 finished with value: 0.9341893878085832 and parameters: {'n_estimators': 52, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'auto', 'bootstrap': False}. Best is trial 3 with value: 0.8091133437973721.\n",
      "[I 2024-08-07 21:39:23,219] Trial 9 finished with value: 0.9341893878085834 and parameters: {'n_estimators': 410, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'auto', 'bootstrap': False}. Best is trial 3 with value: 0.8091133437973721.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 278, 'max_depth': 21, 'min_samples_split': 3, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True}\n",
      "Best RMSE: 0.8091133437973721\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"https://spacefarm:coolguyisyou@mlflow-izqyq2ng5q-du.a.run.app\")\n",
    "mlflow.set_experiment(\"randomforest_regressor_tuning\")  \n",
    "\n",
    "# Define objective function\n",
    "def objective(trial):\n",
    "    with mlflow.start_run(run_name=f\"trial_{trial.number}\"):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 10, 500),\n",
    "            'max_depth': trial.suggest_int('max_depth', 2, 32, log=True),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "            'max_features': trial.suggest_categorical('max_features', ['auto', 'sqrt']),\n",
    "            'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n",
    "        }\n",
    "\n",
    "        model = RandomForestRegressor(**params)  \n",
    "        model.fit(x_train, y_train)  \n",
    "        y_pred = model.predict(x_val)\n",
    "\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        mase = mean_absolute_scaled_error(y_val, y_pred)\n",
    "        rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "        r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "        # Log params and metrics to MLflow\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metrics({\n",
    "                    \"mse\": mse,\n",
    "                    \"rmse\": rmse,\n",
    "                    \"r2\": r2,\n",
    "                    \"mase\": mase\n",
    "        })\n",
    "        \n",
    "        # Use RMSE as the optimization target\n",
    "        return rmse  \n",
    "\n",
    "# Optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=10)  # Adjust n_trials as needed\n",
    "\n",
    "# Print best parameters and score\n",
    "print('Best parameters:', study.best_params)\n",
    "print('Best RMSE:', study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b0b0a3-f2d7-4063-8258-aa0a4b9c0510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "279cd75c-f1e0-43df-bcb4-12c8b5697763",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/07 21:44:33 INFO mlflow.tracking.fluent: Experiment with name 'knn_regressor_tuning' does not exist. Creating a new experiment.\n",
      "[I 2024-08-07 21:44:33,560] A new study created in memory with name: no-name-795ac530-d113-4cc9-b379-6485bcff7e41\n",
      "[I 2024-08-07 21:44:57,595] Trial 0 finished with value: 0.9361153071062217 and parameters: {'n_neighbors': 2, 'weights': 'distance', 'p': 1, 'leaf_size': 30, 'algorithm': 'brute'}. Best is trial 0 with value: 0.9361153071062217.\n",
      "[I 2024-08-07 21:45:23,512] Trial 1 finished with value: 0.8780806269276897 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'p': 2, 'leaf_size': 39, 'algorithm': 'brute'}. Best is trial 1 with value: 0.8780806269276897.\n",
      "[I 2024-08-07 21:45:25,867] Trial 2 finished with value: 0.8197992590581687 and parameters: {'n_neighbors': 17, 'weights': 'distance', 'p': 2, 'leaf_size': 12, 'algorithm': 'ball_tree'}. Best is trial 2 with value: 0.8197992590581687.\n",
      "[I 2024-08-07 21:45:27,697] Trial 3 finished with value: 0.8913340758840183 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'p': 2, 'leaf_size': 11, 'algorithm': 'ball_tree'}. Best is trial 2 with value: 0.8197992590581687.\n",
      "[I 2024-08-07 21:45:52,126] Trial 4 finished with value: 0.8745919857317354 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'p': 1, 'leaf_size': 26, 'algorithm': 'brute'}. Best is trial 2 with value: 0.8197992590581687.\n",
      "[I 2024-08-07 21:45:53,440] Trial 5 finished with value: 0.8202944996966762 and parameters: {'n_neighbors': 16, 'weights': 'distance', 'p': 2, 'leaf_size': 41, 'algorithm': 'kd_tree'}. Best is trial 2 with value: 0.8197992590581687.\n",
      "[I 2024-08-07 21:45:55,450] Trial 6 finished with value: 0.8965393093484351 and parameters: {'n_neighbors': 18, 'weights': 'uniform', 'p': 1, 'leaf_size': 10, 'algorithm': 'kd_tree'}. Best is trial 2 with value: 0.8197992590581687.\n",
      "[I 2024-08-07 21:45:56,657] Trial 7 finished with value: 0.8315483931484859 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'p': 2, 'leaf_size': 29, 'algorithm': 'auto'}. Best is trial 2 with value: 0.8197992590581687.\n",
      "[I 2024-08-07 21:45:57,784] Trial 8 finished with value: 0.8721341965115772 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'p': 2, 'leaf_size': 34, 'algorithm': 'kd_tree'}. Best is trial 2 with value: 0.8197992590581687.\n",
      "[I 2024-08-07 21:45:59,311] Trial 9 finished with value: 0.8444887685988565 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'p': 1, 'leaf_size': 16, 'algorithm': 'auto'}. Best is trial 2 with value: 0.8197992590581687.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_neighbors': 17, 'weights': 'distance', 'p': 2, 'leaf_size': 12, 'algorithm': 'ball_tree'}\n",
      "Best RMSE: 0.8197992590581687\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"https://spacefarm:coolguyisyou@mlflow-izqyq2ng5q-du.a.run.app\")\n",
    "mlflow.set_experiment(\"knn_regressor_tuning\")\n",
    "\n",
    "# Define objective function\n",
    "def objective(trial):\n",
    "    with mlflow.start_run(run_name=f\"trial_{trial.number}\"):\n",
    "        params = {\n",
    "            'n_neighbors': trial.suggest_int('n_neighbors', 1, 20),\n",
    "            'weights': trial.suggest_categorical('weights', ['uniform', 'distance']),\n",
    "            'p': trial.suggest_categorical('p', [1, 2]),\n",
    "            'leaf_size': trial.suggest_int('leaf_size', 10, 50),\n",
    "            # Optional: \n",
    "            'algorithm': trial.suggest_categorical('algorithm', ['auto', 'ball_tree', 'kd_tree', 'brute']),\n",
    "        }\n",
    "\n",
    "        model = KNeighborsRegressor(**params)\n",
    "        model.fit(x_train, y_train)  # Replace x_train, y_train with your data\n",
    "        y_pred = model.predict(x_val)    # Replace x_val with your data\n",
    "\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        mase = mean_absolute_scaled_error(y_val, y_pred)\n",
    "        rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "        r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "        # Log params and metrics to MLflow\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metrics({\n",
    "                    \"mse\": mse,\n",
    "                    \"rmse\": rmse,\n",
    "                    \"r2\": r2,\n",
    "                    \"mase\": mase\n",
    "        })\n",
    "        \n",
    "        # Use RMSE as the optimization target\n",
    "        return rmse  \n",
    "\n",
    "# Optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=10)  # Adjust n_trials as needed\n",
    "\n",
    "# Print best parameters and score\n",
    "print('Best parameters:', study.best_params)\n",
    "print('Best RMSE:', study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8e58c3-0f7b-4542-b5e2-bd63ce6956bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning deep learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a89fe6-e4f7-4684-ad67-9145d45a2796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN\n",
    "x_train = s_train[:,9:]\n",
    "y_train = s_train[:,:9]\n",
    "\n",
    "x_val = s_val[:,9:]\n",
    "y_val = s_val[:,:9]\n",
    "\n",
    "x_test = s_test[:,9:]\n",
    "y_test = s_test[:,:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d02b4fd-d4ea-4630-96f6-8f7f7b0bc76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-08 02:04:53,048] A new study created in memory with name: no-name-efca8051-d334-4175-a60d-f46a8e6b6d83\n",
      "2024-08-08 02:04:54.461954: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-08 02:04:54.462087: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-08-08 02:04:54.462144: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-08-08 02:04:54.462175: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-08-08 02:04:54.462205: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-08-08 02:04:54.482646: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-08-08 02:04:54.482795: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-08-08 02:04:54.483429: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "860/860 [==============================] - 1s 650us/step\n",
      "(27504, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-08 02:05:38,606] Trial 0 finished with value: 0.935632437346627 and parameters: {'num_layers': 1, 'units_per_layer': 448, 'dropout_rate': 0.004913974766539819, 'learning_rate': 0.015787705477566367, 'activation': 'relu'}. Best is trial 0 with value: 0.935632437346627.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "860/860 [==============================] - 1s 664us/step\n",
      "(27504, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-08 02:06:07,791] Trial 1 finished with value: 0.9312636671383824 and parameters: {'num_layers': 1, 'units_per_layer': 128, 'dropout_rate': 0.26384036344897244, 'learning_rate': 0.0019339498316411042, 'activation': 'tanh'}. Best is trial 1 with value: 0.9312636671383824.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "860/860 [==============================] - 1s 786us/step\n",
      "(27504, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-08 02:07:47,033] Trial 2 finished with value: 0.919256428747313 and parameters: {'num_layers': 3, 'units_per_layer': 320, 'dropout_rate': 0.20146505388717534, 'learning_rate': 0.00031453852516781543, 'activation': 'tanh'}. Best is trial 2 with value: 0.919256428747313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "860/860 [==============================] - 1s 848us/step\n",
      "(27504, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-08 02:09:40,125] Trial 3 finished with value: 0.9316052628596879 and parameters: {'num_layers': 3, 'units_per_layer': 320, 'dropout_rate': 0.3736698538079333, 'learning_rate': 0.00010773382091618153, 'activation': 'tanh'}. Best is trial 2 with value: 0.919256428747313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "860/860 [==============================] - 1s 791us/step\n",
      "(27504, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-08 02:10:45,491] Trial 4 finished with value: 0.9100952796690576 and parameters: {'num_layers': 3, 'units_per_layer': 256, 'dropout_rate': 0.13274575070353323, 'learning_rate': 0.005018307204219169, 'activation': 'relu'}. Best is trial 4 with value: 0.9100952796690576.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "860/860 [==============================] - 1s 739us/step\n",
      "(27504, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-08 02:11:18,028] Trial 5 finished with value: 1.0846452072833792 and parameters: {'num_layers': 3, 'units_per_layer': 192, 'dropout_rate': 0.016096455046272662, 'learning_rate': 0.03461962147898827, 'activation': 'tanh'}. Best is trial 4 with value: 0.9100952796690576.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "860/860 [==============================] - 1s 765us/step\n",
      "(27504, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-08 02:12:47,904] Trial 6 finished with value: 0.9930556046233906 and parameters: {'num_layers': 2, 'units_per_layer': 384, 'dropout_rate': 0.03509017773546669, 'learning_rate': 0.08754045025732708, 'activation': 'relu'}. Best is trial 4 with value: 0.9100952796690576.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "860/860 [==============================] - 1s 690us/step\n",
      "(27504, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-08 02:13:25,876] Trial 7 finished with value: 0.9261179231839315 and parameters: {'num_layers': 1, 'units_per_layer': 192, 'dropout_rate': 0.17465982992186324, 'learning_rate': 0.002337552157515334, 'activation': 'relu'}. Best is trial 4 with value: 0.9100952796690576.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "860/860 [==============================] - 1s 709us/step\n",
      "(27504, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-08 02:14:03,873] Trial 8 finished with value: 1.0020666623552401 and parameters: {'num_layers': 2, 'units_per_layer': 192, 'dropout_rate': 0.13987796909340133, 'learning_rate': 0.018135857881756114, 'activation': 'tanh'}. Best is trial 4 with value: 0.9100952796690576.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "860/860 [==============================] - 1s 697us/step\n",
      "(27504, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-08 02:14:36,314] Trial 9 finished with value: 0.9333478285653874 and parameters: {'num_layers': 1, 'units_per_layer': 448, 'dropout_rate': 0.17399589027340773, 'learning_rate': 0.001242640037638423, 'activation': 'tanh'}. Best is trial 4 with value: 0.9100952796690576.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'num_layers': 3, 'units_per_layer': 256, 'dropout_rate': 0.13274575070353323, 'learning_rate': 0.005018307204219169, 'activation': 'relu'}\n",
      "Best RMSE: 0.9100952796690576\n"
     ]
    }
   ],
   "source": [
    "# MLflow Tracking Setup (Modify URI if needed)\n",
    "mlflow.set_tracking_uri(\"https://spacefarm:coolguyisyou@mlflow-izqyq2ng5q-du.a.run.app\")\n",
    "mlflow.set_experiment(\"ANN_regressor_tuning\")\n",
    "\n",
    "# Define objective function\n",
    "def objective(trial):\n",
    "    with mlflow.start_run(nested=True, run_name=f\"trial_{trial.number}\"):\n",
    "        # Hyperparameters to tune\n",
    "        num_layers = trial.suggest_int('num_layers', 1, 3)\n",
    "        units_per_layer = trial.suggest_categorical('units_per_layer', [64, 128, 192, 256, 320, 384, 448])\n",
    "        dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.5)\n",
    "        learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-1, log=True)\n",
    "        activation = trial.suggest_categorical('activation', ['relu', 'tanh'])\n",
    "        \n",
    "        # Early Stopping Callback\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "        # Build model\n",
    "        model = keras.Sequential()\n",
    "        model.add(keras.layers.InputLayer(input_shape=(x_train.shape[1],)))\n",
    "\n",
    "        for i in range(num_layers):\n",
    "            model.add(Dense(units_per_layer, activation=activation))\n",
    "            model.add(Dropout(dropout_rate))\n",
    "\n",
    "        model.add(Dense(y_train.shape[1]))  # Output layer for regression\n",
    "\n",
    "        # Compile model\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), \n",
    "                      loss='mean_squared_error')\n",
    "\n",
    "        # Train model with Early Stopping\n",
    "        model.fit(x_train, y_train, epochs=100,  # Potentially increase max epochs since early stopping is used\n",
    "                  batch_size=32, \n",
    "                  validation_data=(x_val, y_val),\n",
    "                  callbacks=[early_stopping],\n",
    "                  verbose=0)\n",
    "\n",
    "        # Evaluate model\n",
    "        y_pred = model.predict(x_val)  # Flatten for easier metric calculation\n",
    "        print(y_pred.shape)\n",
    "        \n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        mase = mean_absolute_scaled_error(y_val, y_pred)\n",
    "        rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "        r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "        # Log params and metrics to MLflow\n",
    "        mlflow.log_params(trial.params)\n",
    "        mlflow.log_metrics({\n",
    "                    \"mse\": mse,\n",
    "                    \"rmse\": rmse,\n",
    "                    \"r2\": r2,\n",
    "                    \"mase\": mase\n",
    "        })\n",
    "        \n",
    "    return rmse\n",
    "\n",
    "\n",
    "# Optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=10)  # Adjust n_trials as needed\n",
    "\n",
    "# Print best parameters and score\n",
    "print('Best parameters:', study.best_params)\n",
    "print('Best RMSE:', study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2bbaaf-c2c6-4a78-b61a-1db8a0c7d7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7be30b4-bc15-48b3-807d-6d5998e081e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-08 12:18:47,395] A new study created in memory with name: no-name-9b4f9f0d-1f3d-4cd9-a9d5-f62d9a014754\n",
      "2024-08-08 12:18:48.913887: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-08 12:18:48.914012: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-08-08 12:18:48.914064: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-08-08 12:18:48.914097: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-08-08 12:18:48.914127: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-08-08 12:18:49.010168: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-08-08 12:18:49.010938: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-08-08 12:18:49.011864: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "860/860 [==============================] - 3s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-08 12:24:31,917] Trial 0 finished with value: 0.9950036054909942 and parameters: {'rnn_type': 'GRU', 'num_layers': 3, 'units_per_layer': 320, 'dropout_rate': 0.3010771152892583, 'learning_rate': 0.027401270972907985, 'activation': 'relu', 'use_attention': True, 'attention_units': 124}. Best is trial 0 with value: 0.9950036054909942.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "860/860 [==============================] - 1s 796us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-08 12:25:38,353] Trial 1 finished with value: 0.920807772022422 and parameters: {'rnn_type': 'SimpleRNN', 'num_layers': 1, 'units_per_layer': 256, 'dropout_rate': 0.4942531619965081, 'learning_rate': 0.00959535827384181, 'activation': 'relu', 'use_attention': False, 'attention_units': 90}. Best is trial 1 with value: 0.920807772022422.\n"
     ]
    }
   ],
   "source": [
    "# Attention Layer (You can use a pre-built one or implement your own)\n",
    "class AttentionLayer(Layer):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "        self.W = Dense(units)\n",
    "        self.V = Dense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        score = self.V(tf.nn.tanh(self.W(inputs)))\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = attention_weights * inputs\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        return context_vector\n",
    "\n",
    "def reshape_for_rnn(X):\n",
    "    # Assuming X has shape (num_samples, num_features) for ANN\n",
    "    num_samples = X.shape[0]\n",
    "    time_steps = 1  # If each sample is a single time step\n",
    "    num_features = X.shape[1]\n",
    "    return X.reshape(num_samples, time_steps, num_features)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# MLflow Tracking Setup\n",
    "mlflow.set_tracking_uri(\"https://spacefarm:coolguyisyou@mlflow-izqyq2ng5q-du.a.run.app\")\n",
    "mlflow.set_experiment(\"rnn_regressor_tuning_with_attention\")\n",
    "\n",
    "# Objective Function\n",
    "def objective(trial):\n",
    "    with mlflow.start_run(nested=True, run_name=f\"trial_{trial.number}\"):\n",
    "        # Hyperparameters\n",
    "        rnn_type = trial.suggest_categorical('rnn_type', ['SimpleRNN', 'LSTM', 'GRU'])\n",
    "        num_layers = trial.suggest_int('num_layers', 1, 3)\n",
    "        units_per_layer = trial.suggest_categorical('units_per_layer', [64, 128, 192, 256, 320, 384, 448])  \n",
    "        dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.5)\n",
    "        learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-1, log=True)\n",
    "        activation = trial.suggest_categorical('activation', ['relu', 'tanh'])\n",
    "\n",
    "        # Attention Hyperparameters\n",
    "        use_attention = trial.suggest_categorical('use_attention', [True, False]) # NEW: Hyperparameter for attention\n",
    "        attention_units = trial.suggest_int('attention_units', 32, 128)  # Adjust as needed\n",
    "\n",
    "        # Early Stopping\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "        X_train = reshape_for_rnn(x_train)  # Reshape for RNN\n",
    "        X_val = reshape_for_rnn(x_val)    # Reshape for RNN\n",
    "\n",
    "        # Build model\n",
    "        model = keras.Sequential()\n",
    "        input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "\n",
    "        for i in range(num_layers):\n",
    "            return_sequences = True if i < num_layers - 1 or use_attention else False  # For Attention, the last RNN layer should return sequences\n",
    "            if rnn_type == 'SimpleRNN':\n",
    "                model.add(SimpleRNN(units_per_layer, activation=activation, return_sequences=return_sequences, input_shape=input_shape))\n",
    "            elif rnn_type == 'LSTM':\n",
    "                model.add(LSTM(units_per_layer, activation=activation, return_sequences=return_sequences, input_shape=input_shape))\n",
    "            else:  # GRU\n",
    "                model.add(GRU(units_per_layer, activation=activation, return_sequences=return_sequences, input_shape=input_shape))\n",
    "            model.add(Dropout(dropout_rate))\n",
    "        \n",
    "        # Flatten and Attention/Dense Layers\n",
    "        if use_attention:\n",
    "            model.add(AttentionLayer(attention_units))\n",
    "            model.add(Dense(y_train.shape[1]))  # 9 outputs after attention\n",
    "        else:  \n",
    "            if return_sequences:\n",
    "                model.add(Flatten())  # Flatten if the last RNN layer returned a sequence\n",
    "            model.add(Dense(y_train.shape[1]))  # 9 outputs without attention\n",
    "\n",
    "        \n",
    "\n",
    "        # Compile model\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss='mse')\n",
    "\n",
    "        # Train model with Early Stopping\n",
    "        model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "        # Evaluate model\n",
    "        y_pred = model.predict(X_val)\n",
    "        \n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        mase = mean_absolute_scaled_error(y_val, y_pred)\n",
    "        rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "        r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "        # Log params and metrics to MLflow\n",
    "        mlflow.log_params(trial.params)\n",
    "        mlflow.log_metrics({\n",
    "                    \"mse\": mse,\n",
    "                    \"rmse\": rmse,\n",
    "                    \"r2\": r2,\n",
    "                    \"mase\": mase\n",
    "        })\n",
    "    return rmse\n",
    "\n",
    "\n",
    "# Optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=10) \n",
    "\n",
    "# Print results\n",
    "print('Best parameters:', study.best_params)\n",
    "print('Best RMSE:', study.best_value)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-tensorflow-tensorflow",
   "name": "workbench-notebooks.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m123"
  },
  "kernelspec": {
   "display_name": "venv-cuda",
   "language": "python",
   "name": "venv-cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
